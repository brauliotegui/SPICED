{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Text Classification: Lyrics model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a text classification model to predict the artist from a piece of text.\n",
    "\n",
    "- Download HTML pages\n",
    "- Get a list of song urls\n",
    "- Extract lyrics from song urls\n",
    "- Convert text to numbers by applying the Bag Of Words method\n",
    "- Build and train a Naive Bayes classifier\n",
    "- Balance out your dataset\n",
    "- Write a command-line interface\n",
    "- Give a 5-minute lightning talk by the end of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download HTML pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose the URL you want to request\n",
    "url = 'https://www.lyrics.com/artist/Funkadelic/4323'\n",
    "\n",
    "# Send the request\n",
    "request = requests.get(url)\n",
    "\n",
    "# Check the status code in order to assess wether our request was succesful\n",
    "request.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# requests.text will return the html file of the website as a string\n",
    "type(request.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the html in a txt file and search in an editor\n",
    "with open('Funkadelic.txt', 'w') as file:\n",
    "    file.write(request.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find and save all links for lyrics as text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_all_lyrics(url, directory):\n",
    "    \"\"\"\n",
    "    Download each song lyrics from every lyric html page from the artist page.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url = url link of the artist page\n",
    "    directory = directory where you want to save all the file\n",
    "    both parameters need to be strings\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    download song files into chosen directory.\n",
    "    \n",
    "    \"\"\"\n",
    "    #DOWNLOAD ARTIST URL AS TEXT FILE\n",
    "    request = requests.get(url)         # Send the request\n",
    "    with open(str(url.split('/')[-2]) + '.txt', 'w') as file:     # Save the html in a txt file and search in an editor\n",
    "        file.write(request.text)\n",
    "        \n",
    "    #CREATE BEAUTIFULSOUP FOR PARSING AND SELECTING LYRIC LINKS\n",
    "    text = request.text                # Get donwloaded text file from original url\n",
    "    artist_soup = BeautifulSoup(text, 'html.parser')    #Use beautifulsoup for parsing\n",
    "    \n",
    "    \n",
    "    #LOOP FOR ADDING ALL LYRIC LINKS INTO A LIST\n",
    "    links = []   # Create list with links\n",
    "    for td in artist_soup.find_all('td'):\n",
    "        if \"tal\" in td.get('class',[]):                                      # selection according to parsing\n",
    "              links.append('https://www.lyrics.com' + td.find('a')['href'])  # append each link into the list with complete url\n",
    "                \n",
    "    #LOOP TO CREATE LYRIC TEXT FILES FOR EACH LYRIC LINK\n",
    "    for i in range(len(links)):\n",
    "        temp_url = links[i]              #create temporary links for each link on the links list\n",
    "        title = temp_url.split('/')[-1]  #create title based on the temp lyric url\n",
    "\n",
    "        temp_req = requests.get(temp_url) #request each temp lyric link\n",
    "\n",
    "        with open(directory + title + '.txt',  'w') as file:\n",
    "            soup_artist = BeautifulSoup(temp_req.text)    #create a bsoup out of each lyric file\n",
    "            lyrics = soup_artist.pre.get_text()           #get only the text from lyrics\n",
    "            file.writelines(lyrics)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_all_lyrics('https://www.lyrics.com/artist/Danger-Doom/742954', 'DangerDoom_lyrics/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_all_lyrics('https://www.lyrics.com/artist/MF-Doom/300089', 'MFDOOM_lyrics/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a list with every lyrics corpus and a list with the artist name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corpuslist(directory, corpus_list, label_list, artist_name):\n",
    "    \"\"\"\n",
    "    Create a list out of every song lyrics downloaded.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Directory = the directory where you want to get all files from and storage the text\n",
    "    in the corpus list.Directory must be passed as a string\n",
    "    corpus_list = name of the list to storage songs lyrics\n",
    "    label_list = name of the list to storage artist name\n",
    "    artist_name = name of the artist, must be passed as string\n",
    "    \n",
    "    CORPUS = []    #list where all songs corpus will be stored\n",
    "    LABELS = []    #lsit where artist name will be stored\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    a list, in which each item is a song lyric corpus, and a list with the artist name.\n",
    "\n",
    "    \"\"\"\n",
    "    #LOOP FOR ADDING LYRIC FILES INTO A LIST\n",
    "    list = os.listdir(directory)\n",
    "    \n",
    "\n",
    "    for i in range(len(list)):\n",
    "        title = list[i]\n",
    "        label_list.append(artist_name)\n",
    "\n",
    "        with open(directory + title,'r') as reader:\n",
    "\n",
    "            doc= reader.read()\n",
    "            doc.lower()\n",
    "            doc.split()\n",
    "            reader.close\n",
    "            corpus_list.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CORPUS_1 = []\n",
    "LABEL_1 = []\n",
    "\n",
    "create_corpuslist('Funkadelic_lyrics/', CORPUS_1, LABEL_1, 'Funkadelic')\n",
    "\n",
    "len(CORPUS_1) == len(LABEL_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CORPUS_2 = []\n",
    "LABEL_2 = []\n",
    "\n",
    "create_corpuslist('MFDOOM_lyrics/', CORPUS_2, LABEL_2, 'MF DOOM')\n",
    "\n",
    "len(CORPUS_2) == len(LABEL_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomOverSampler Model\n",
    "ros = RandomOverSampler(random_state=10, sampling_strategy={1: 1000})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine artitsts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS = CORPUS_1 + CORPUS_2\n",
    "LABELS = LABEL_1 + LABEL_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(text, labels):\n",
    "    \"\"\"\n",
    "    Trains a scikit-learn classification model on text.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text : list\n",
    "    labels : list\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    model : Trained scikit-learn model.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    cv = CountVectorizer(stop_words='english')\n",
    "    tf = TfidfTransformer()\n",
    "    rf = RandomForestClassifier()\n",
    "    \n",
    "    model = make_pipeline(cv, tf, rf)\n",
    "    model.fit(text, labels)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, new_text):\n",
    "    \"\"\"\n",
    "    Takes the pre-trained model pipeline and predicts new artist based on unseen text.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : Trained scikit-learn model pipeline.\n",
    "    new_text : str\n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    prediction : str\n",
    "    \n",
    "    \"\"\"\n",
    "    new_text = [new_text]\n",
    "    prediction = model.predict(new_text)\n",
    "    \n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Funkadelic'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = train_model(CORPUS, LABELS)\n",
    "prediction = predict(model, 'Walking and living through this')\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please Enter Some Text: danger\n",
      "Here is your prediction!\n",
      "MF DOOM\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Whatever happens after this line, execute it when running \"python lyrics_classifier.py\"\n",
    "    # and DO NOT execute these lines of code if things from this script are imported from other scripts.\n",
    "\n",
    "    model = train_model(CORPUS, LABELS)\n",
    "    user_input = input('Please Enter Some Text: ')\n",
    "\n",
    "    prediction = predict(model, user_input)\n",
    "    print('Here is your prediction!')\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
