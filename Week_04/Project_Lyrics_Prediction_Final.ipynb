{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Text Classification: Lyrics model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a text classification model to predict the artist from a piece of text.\n",
    "\n",
    "- Download HTML pages\n",
    "- Get a list of song urls\n",
    "- Extract lyrics from song urls\n",
    "- Convert text to numbers by applying the Bag Of Words method\n",
    "- Build and train a Naive Bayes classifier\n",
    "- Balance out your dataset\n",
    "- Write a command-line interface\n",
    "- Give a 5-minute lightning talk by the end of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, CategoricalNB\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download HTML pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find and save all links for lyrics as text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_all_lyrics(url, directory):\n",
    "    \"\"\"\n",
    "    Download each song lyrics from every lyric html page from the artist page.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url = url link of the artist page\n",
    "    directory = directory where you want to save all the file\n",
    "    both parameters need to be strings\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    download song files into chosen directory.\n",
    "    \n",
    "    \"\"\"\n",
    "    #DOWNLOAD ARTIST URL AS TEXT FILE\n",
    "    request = requests.get(url)         # Send the request\n",
    "    with open(str(url.split('/')[-2]) + '.txt', 'w') as file:     # Save the html in a txt file and search in an editor\n",
    "        file.write(request.text)\n",
    "        \n",
    "    #CREATE BEAUTIFULSOUP FOR PARSING AND SELECTING LYRIC LINKS\n",
    "    text = request.text                # Get donwloaded text file from original url\n",
    "    artist_soup = BeautifulSoup(text, 'html.parser')    #Use beautifulsoup for parsing\n",
    "    \n",
    "    \n",
    "    #LOOP FOR ADDING ALL LYRIC LINKS INTO A LIST\n",
    "    links = []   # Create list with links\n",
    "    for td in artist_soup.find_all('td'):\n",
    "        if \"tal\" in td.get('class',[]):                                      # selection according to parsing\n",
    "              links.append('https://www.lyrics.com' + td.find('a')['href'])  # append each link into the list with complete url\n",
    "                \n",
    "    \n",
    "    #LOOP TO CREATE LYRIC TEXT FILES FOR EACH LYRIC LINK\n",
    "    for i in range(len(links)):\n",
    "        temp_url = links[i]              #create temporary links for each link on the links list\n",
    "        title = temp_url.split('/')[-1]  #create title based on the temp lyric url\n",
    "\n",
    "        temp_req = requests.get(temp_url) #request each temp lyric link\n",
    "\n",
    "        with open(directory + title + '.txt',  'w') as file:\n",
    "            soup_artist = BeautifulSoup(temp_req.text)    #create a bsoup out of each lyric file\n",
    "            lyrics = soup_artist.pre.get_text()           #get only the text from lyrics\n",
    "            file.writelines(lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_all_lyrics('https://www.lyrics.com/artist/Black-Sabbath/3693', 'BLACKSabbath/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_all_lyrics('https://www.lyrics.com/artist/Led-Zeppelin/4739', 'LEDZeppelin/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_all_lyrics('https://www.lyrics.com/artist/Funkadelic/4323', 'FUNKADELIC/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a list with every lyrics corpus and a list with the artist name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corpuslist(directory, artist_name):\n",
    "    \"\"\"\n",
    "    Create a list out of every song lyrics downloaded.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Directory = the directory where you want to get all files from and storage the text\n",
    "    in the corpus list.Directory must be passed as a string,\n",
    "    artist_name = name of the artist, must be passed as string\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    a list, in which each item is a song lyric corpus, and a list with the artist name.\n",
    "\n",
    "    \"\"\"\n",
    "    #LOOP FOR ADDING LYRIC FILES INTO A LIST\n",
    "    list = os.listdir(directory)\n",
    "    list_size = len(label)  #original size\n",
    "    \n",
    "    for i in range(len(list)):\n",
    "        title = list[i]\n",
    "        label.append(artist_name)\n",
    "\n",
    "        with open(directory + title,'r') as reader:\n",
    "\n",
    "            doc= reader.read()\n",
    "            doc.lower()\n",
    "            doc.split()\n",
    "            reader.close\n",
    "            corpus.append(doc)\n",
    "            \n",
    "            \n",
    "    print (artist_name, (len(label) - list_size))\n",
    "    print ('Do we have as many song lyrics as artist indices?: '\n",
    "               + str(len(corpus) == len(label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black Sabbath 296\n",
      "Do we have as many song lyrics as artist indices?: True\n"
     ]
    }
   ],
   "source": [
    "create_corpuslist('BLACKSabbath/', 'Black Sabbath')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Led Zeppelin 224\n",
      "Do we have as many song lyrics as artist indices?: True\n"
     ]
    }
   ],
   "source": [
    "create_corpuslist('LEDZeppelin/', 'Led Zeppelin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funkadelic 54\n",
      "Do we have as many song lyrics as artist indices?: True\n"
     ]
    }
   ],
   "source": [
    "create_corpuslist('FUNKADELIC/', 'Funkadelic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectors_and_df(corpus, label):\n",
    "    \"\"\"creates vectors for songs and returns dataframe with songs as word vectors \n",
    "    by all artists\"\"\"\n",
    "    \n",
    "    cv = TfidfVectorizer(stop_words=\"english\")\n",
    "    cv.fit(corpus)\n",
    "    corpus_vecs = cv.transform(corpus)\n",
    "    \n",
    "    return pd.DataFrame(corpus_vecs.todense(), index=label, \n",
    "                        columns=cv.get_feature_names()), cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results into dataframe, keep cv for later prediction\n",
    "df, cv = vectors_and_df(corpus, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target column\n",
    "X = df\n",
    "y = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test for models scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_params = {\n",
    "    \"MultinomialNB\": {\"alpha\": 0.005},\n",
    "    \"CategoricalNB\": {\"alpha\": 0.01},\n",
    "    \"RandomForestClassifier\": {\n",
    "        \"n_estimators\": 500,\n",
    "        \"max_depth\": 200,\n",
    "        \"max_features\": \"auto\",\n",
    "        \"n_jobs\": -1,\n",
    "        \"random_state\": 1,\n",
    "    },\n",
    "    \"LogisticRegression\": {\"C\": 1e6},\n",
    "}\n",
    "\n",
    "def train_models(models_params):\n",
    "    \"\"\"trains models on corpus and returns dataframe with scores\"\"\"\n",
    "    \n",
    "    scores = {}\n",
    "    for model in models_params:\n",
    "        if model == \"LogisticRegression\":\n",
    "            m = LogisticRegression(**models_params[model])\n",
    "        elif model == \"RandomForestClassifier\":\n",
    "            m = RandomForestClassifier(**models_params[model])\n",
    "        elif model == \"MultinomialNB\":\n",
    "            m = MultinomialNB(**models_params[model])\n",
    "        elif model == \"CategoricalNB\":\n",
    "            m = MultinomialNB(**models_params[model])\n",
    "\n",
    "        m.fit(Xtrain, ytrain)\n",
    "        score_train = m.score(Xtrain, ytrain)\n",
    "        score_test = m.score(Xtest, ytest)\n",
    "        scores[f\"{model}\"] = {\n",
    "            \"params\": models_params[model],\n",
    "            \"train score\": score_train,\n",
    "            \"test score\": score_test,\n",
    "            }\n",
    "    return pd.DataFrame(scores).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>{'alpha': 0.005}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.930435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CategoricalNB</th>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>0.997821</td>\n",
       "      <td>0.93913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>{'n_estimators': 500, 'max_depth': 200, 'max_f...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.930435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>{'C': 1000000.0}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   params  \\\n",
       "MultinomialNB                                            {'alpha': 0.005}   \n",
       "CategoricalNB                                             {'alpha': 0.01}   \n",
       "RandomForestClassifier  {'n_estimators': 500, 'max_depth': 200, 'max_f...   \n",
       "LogisticRegression                                       {'C': 1000000.0}   \n",
       "\n",
       "                       train score test score  \n",
       "MultinomialNB                    1   0.930435  \n",
       "CategoricalNB             0.997821    0.93913  \n",
       "RandomForestClassifier           1   0.930435  \n",
       "LogisticRegression               1   0.913043  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores = train_models(models_params)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train data with best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9930313588850174"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train on most promising model\n",
    "model = \"MultinomialNB\"\n",
    "m = MultinomialNB(**models_params[model])\n",
    "m.fit(X, y)\n",
    "m.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(new_text):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes the pre-trained model pipeline and predicts new artist based on unseen text.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : Trained scikit-learn model pipeline.\n",
    "    new_text : str\n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    prediction : str\n",
    "    \n",
    "    \"\"\"\n",
    "    songlyrics = [new_text]\n",
    "    # transform song into vector matrix\n",
    "    new_song_vecs = cv.transform(songlyrics)\n",
    "    ynew = new_song_vecs.todense()\n",
    "    \n",
    "    prediction = m.predict(ynew)\n",
    "    \n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please Enter Some Text: Now I've got that feeling once again\n",
      "Here is your prediction!\n",
      "Black Sabbath\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Whatever happens after this line, execute it when running \"python lyrics_classifier.py\"\n",
    "    # and DO NOT execute these lines of code if things from this script are imported from other scripts.\n",
    "    \n",
    "    user_input = input('Please Enter Some Text: ')\n",
    "\n",
    "    prediction = predict(user_input)\n",
    "    print('Here is your prediction!')\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
